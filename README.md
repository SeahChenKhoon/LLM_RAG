# Retrieval-Augmented Generation Evaluation Pipeline

A document-grounded question answering system with LangChain + OpenAI that evaluates generated responses using both ROUGE and RAGAS metrics.

---

## ğŸ§  Project Overview

This pipeline ingests PDFs, splits them semantically, stores them in a FAISS vector store with OpenAI embeddings, and answers questions using a Retrieval-Augmented Generation (RAG) chain. It supports both batch evaluation and interactive querying, and provides automatic scoring using ROUGE and RAGAS.

**Use cases:**
- Evaluating QA system performance on domain-specific documents
- Benchmarking retrieval quality and answer faithfulness
- Running both automated and human-in-the-loop evaluations

---
## ğŸ”§ Features

- ğŸ“„ PDF document loading via `PyPDFLoader`
- âœ‚ï¸ Semantic chunking with `SemanticChunker`
- ğŸ§  RAG chain using `ChatOpenAI` and `RetrievalQA`
- ğŸ“Š ROUGE and RAGAS scoring
- ğŸ§ª Batch mode with CSV input/output
- ğŸ’¬ Interactive mode with live querying
- ğŸ’¾ FAISS index persistence

---

## ğŸ“ Project Structure

```text
â”œâ”€â”€ documents/                      # PDF documents to index
â”‚   â””â”€â”€ Coffee_and_health.pdf       # Sample PDF to RAG
â”œâ”€â”€ questions/                      # CSV files with questions and ground 
â”‚   â””â”€â”€ Questions.csv               # Batch questions storage
â”œâ”€â”€ results/                        # Output folder for evaluation results
â”‚   â””â”€â”€ result_20250324_1155.csv    # Example result file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cls_Env.py                  # Loads environment variables and config
â”‚   â”œâ”€â”€ util.py                     # Config utility functions
â”‚   â”œâ”€â”€ rag_document_retrieval.py   # RAG pipeline entry point for processing, QA, and evaluation
â”‚   â””â”€â”€ config.yml                  # Central YAML configuration file for paths, model, and runtime settings
â”œâ”€â”€ .env                            # Environment variable file
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # ReadMe file
```

## âš™ï¸ Setup
### 1. Clone and install

```bash
git clone https://github.com/SeahChenKhoon/LLM_RAG.git
cd LLM_RAG
```


![Clone and install](./images/01_Clone_and_install.png)

### 2. Set Up Virtual Environment and Install Dependencies
This step may take a few minutes to complete.
```bash
python -m venv .venv
source .venv\\Scripts\\activate # On On macOS/Linux: source venv/bin/activate  
pip install -r requirements.txt
```

![Set Up Virtual Environment and Install Dependencies](./images/02_Set_Up_Virtual_Environment_and_Install_Dependencies.png)


### 3. Configure environment
Copy .env_sample to .env and update as needed:
```bash
cp sample.env .env
```

![Configure environment](./images/03_Configure_environment.png)

| Variable             | Description                                             |
|----------------------|---------------------------------------------------------|
| `YAML_CONFIG_PATH`   | Path to the central YAML configuration file            |
| `OPENAI_API_KEY`     | Your OpenAI API key                                     |
| `OPENAI_MODEL_NAME`  | The OpenAI model used for inference (e.g., `gpt-4`)     |
| `LLM_TEMPERATURE`    | LLM response creativity and randomness (e.g., `0.2`)    |


## ğŸš€ Usage

### Batch Mode (from CSV)
```bash
  PYTHONPATH=. python src/rag_document_retrieval.py
```

When prompted:
Enter `batch` to run from CSV or `interactive` to type questions: `batch`

![Batch Mode](./images/Run_Batch.png)

### Interactive Mode
```bash
  PYTHONPATH=. python src/rag_document_retrieval.py.py
```
When prompted:
Enter `batch` to run from CSV or `interactive` to type questions: `interactive`

![Interactive Mode](./images/Run_Interactive.png)

## ğŸ“Š Metrics

- ROUGE-1, ROUGE-2, ROUGE-L: Lexical overlap
- RAGAS:
  - answer_relevancy
  - context_precision
  - context_recall
  - faithfulness
  - semantic_similarity

Results saved to a timestamped file, e.g.:
```text
results/result_20250602_1043.csv
```

## âœ… Requirements
- Python 3.8+
- langchain
- openai
- ragas
- datasets
- rouge_score
- python-dotenv
- pandas

